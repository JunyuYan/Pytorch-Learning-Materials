{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9+Xt9MXg/Ja/e+wg3zoW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunyuYan/Pytorch-Learning-Materials/blob/main/Quick_Start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic 1 Data Processing:**\n",
        "\n",
        "Two primitives to work with data:\n",
        "> torch.utils.data.DataLoader\n",
        "\n",
        "> torch.utils.data.Dataset"
      ],
      "metadata": {
        "id": "4AmTvf3YnMPl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GO05G1afnGQ7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch provides domain-specific libraries as such as TorchText, TorchVision, and TorchAudio, all of which include datasets. In this tutorial, we take TorchVision as an example."
      ],
      "metadata": {
        "id": "LOhAGpITo7Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from open datasets\n",
        "# For TorchVision, each dataset includes two augments: transform and target_transform\n",
        "# to modify the samples and labels respectively\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "testing_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "Nlj0THZApwnD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader wraps an iterable over our datasets, and supports automatic batching, sampling, shuffling and multiprocess data loading. The dataset\n",
        "can be passed as an augment to DataLoader"
      ],
      "metadata": {
        "id": "mkfUL1YZsQ2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "# Each element in the dataloader iterable will return a batch of 64 features and labels\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\") # 一个batch数据大小\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\") # 一个batch标签大小\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7CnPmcLwNe1",
        "outputId": "3478528a-8835-4069-ae24-b43fb5cd9bf5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic 2: Create Model**\n",
        "\n",
        "\n",
        "Create a class that inherits from nn.Module\n",
        "\n",
        "\n",
        "\\_\\_init\\_\\_: define the layers of the network\n",
        "\n",
        "\n",
        "forward: specify how data will pass through the network\n",
        "\n",
        "\n",
        "device: define how to accelerate operations"
      ],
      "metadata": {
        "id": "ndlO8bWwyDPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.linear import Linear\n",
        "# Create a simple neural network\n",
        "# Define the accelerator for training\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-dlmp3czIwt",
        "outputId": "86a7826c-9c24-45f0-9a3d-a8009c611e8c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic 3: Train and Test the model**\n",
        "\n",
        "\n",
        "Training: The model makes predictions on the training data, and then\n",
        "backpropogate the prediction error to adjust the model's parameters.\n",
        "The training process is conducted over several iterations (epochs). During\n",
        "wach epoch, the model learns to make better predictions.  \n",
        "\n",
        "\n",
        "Testing: Evaluate the model's performance on the new test dataset\n"
      ],
      "metadata": {
        "id": "xDxOo2Ah5Kdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "V3u_To1M0TdB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training process\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropogate\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Print loss for every 100 batchs\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1)*len(X)\n",
        "      print(f\"loss:{loss:>7f} [current:{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "ig-VHj9tdH1H"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define test process\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "       X, y = X.to(device), y.to(device)\n",
        "       pred = model(X)\n",
        "       test_loss += loss_fn(pred, y).item()\n",
        "       correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "H5dxQ4BTdQrd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n---------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqbXjg-7jnub",
        "outputId": "d56f4357-6d11-470c-e31e-057f1df3fd37"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "---------------------------\n",
            "loss:2.297778 [current:   64/60000]\n",
            "loss:2.281790 [current: 6464/60000]\n",
            "loss:2.271369 [current:12864/60000]\n",
            "loss:2.267102 [current:19264/60000]\n",
            "loss:2.245389 [current:25664/60000]\n",
            "loss:2.226614 [current:32064/60000]\n",
            "loss:2.230417 [current:38464/60000]\n",
            "loss:2.200032 [current:44864/60000]\n",
            "loss:2.189414 [current:51264/60000]\n",
            "loss:2.165955 [current:57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 2.158766 \n",
            "\n",
            "Epoch 2\n",
            "---------------------------\n",
            "loss:2.166434 [current:   64/60000]\n",
            "loss:2.150142 [current: 6464/60000]\n",
            "loss:2.103571 [current:12864/60000]\n",
            "loss:2.113746 [current:19264/60000]\n",
            "loss:2.066442 [current:25664/60000]\n",
            "loss:2.018605 [current:32064/60000]\n",
            "loss:2.038460 [current:38464/60000]\n",
            "loss:1.967390 [current:44864/60000]\n",
            "loss:1.954375 [current:51264/60000]\n",
            "loss:1.892532 [current:57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.5%, Avg loss: 1.890121 \n",
            "\n",
            "Epoch 3\n",
            "---------------------------\n",
            "loss:1.924523 [current:   64/60000]\n",
            "loss:1.884631 [current: 6464/60000]\n",
            "loss:1.777371 [current:12864/60000]\n",
            "loss:1.804583 [current:19264/60000]\n",
            "loss:1.705266 [current:25664/60000]\n",
            "loss:1.664614 [current:32064/60000]\n",
            "loss:1.679102 [current:38464/60000]\n",
            "loss:1.593570 [current:44864/60000]\n",
            "loss:1.599112 [current:51264/60000]\n",
            "loss:1.495413 [current:57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.517114 \n",
            "\n",
            "Epoch 4\n",
            "---------------------------\n",
            "loss:1.591195 [current:   64/60000]\n",
            "loss:1.545060 [current: 6464/60000]\n",
            "loss:1.404565 [current:12864/60000]\n",
            "loss:1.460818 [current:19264/60000]\n",
            "loss:1.353498 [current:25664/60000]\n",
            "loss:1.355279 [current:32064/60000]\n",
            "loss:1.367880 [current:38464/60000]\n",
            "loss:1.307793 [current:44864/60000]\n",
            "loss:1.327964 [current:51264/60000]\n",
            "loss:1.224661 [current:57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 1.252797 \n",
            "\n",
            "Epoch 5\n",
            "---------------------------\n",
            "loss:1.338689 [current:   64/60000]\n",
            "loss:1.309106 [current: 6464/60000]\n",
            "loss:1.152940 [current:12864/60000]\n",
            "loss:1.242288 [current:19264/60000]\n",
            "loss:1.126800 [current:25664/60000]\n",
            "loss:1.157323 [current:32064/60000]\n",
            "loss:1.178460 [current:38464/60000]\n",
            "loss:1.131793 [current:44864/60000]\n",
            "loss:1.158677 [current:51264/60000]\n",
            "loss:1.067683 [current:57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.090204 \n",
            "\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic 4: Save and Load the model**\n",
        "\n",
        "\n",
        "Save the model (save model's parameters):\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "\n",
        "Load the model (recreate the model and load model state dictionary):\n",
        "torch.load(\"model.pth\")\n"
      ],
      "metadata": {
        "id": "7h6YC9vjp9RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Successfully save the pytorch model\")\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7_UsOOlLr8",
        "outputId": "9c831c66-f27d-4cc0-a1ba-34a9bcfb8b51"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully save the pytorch model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}
